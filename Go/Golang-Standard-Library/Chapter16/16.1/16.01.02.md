## 临时对象池-总结

- **(1) 多个 goroutine 都需创建同一对象时，可能导致对象的创建数目剧增。**
- **(2) `sync.Pool` 对象池让 goroutine 从池中获取出一个对象而非创建。**
- **(3) `sync.Pool` 提供两个方法 :Get 和 Put 和一个初始化回调函数 New。**
- **(4) `sync.Pool` 存在回收机制，系统自动 GC 时触发 pool.go 中的 poolCleanup 函数。**
- **(5) `poolCleanup` 函数会把 Pool 中所有 goroutine 创建的对象都进行销毁。这可能导致往 pool 中 PUT 对象后，GC 触发，导致 GET 函数重新调用 New 函数，临时创建对象存放到 pool 中。**
- **(6) `sync.Pool` 不适合做持久保存的对象池（如连接池），而是临时对象池降低 GC 的压力。**

## 临时对象池

当多个 goroutine 都需要创建同一个对象的时候，如果 goroutine 过多，可能导致对象的创建数目剧增。
而对象又是占用内存的，进而导致的就是内存回收的 GC 压力徒增。造成“并发大－占用内存大－ GC 缓慢－处理并发能力降低－并发更大”这样的恶性循环。
在这个时候，我们非常迫切需要有一个对象池，每个 goroutine 不再自己单独创建对象，而是从对象池中获取出一个对象（如果池中已经有的话）。
这就是 sync.Pool 出现的目的了。

sync.Pool 的使用非常简单，提供两个方法 :Get 和 Put 和一个初始化回调函数 New。

看下面这个例子：

```golang
// keyBufPool returns []byte buffers for use by PickServer's call to
// crc32.ChecksumIEEE to avoid allocations. (but doesn't avoid the
// copies, which at least are bounded in size and small)
var keyBufPool = sync.Pool{
    New: func() interface{} {
        b := make([]byte, 256)
        return &b
    },
}

func (ss *ServerList) PickServer(key string) (net.Addr, error) {
    ss.mu.RLock()
    defer ss.mu.RUnlock()
    if len(ss.addrs) == 0 {
        return nil, ErrNoServers
    }
    if len(ss.addrs) == 1 {
        return ss.addrs[0], nil
    }
    bufp := keyBufPool.Get().(*[]byte)
    n := copy(*bufp, key)
    cs := crc32.ChecksumIEEE((*bufp)[:n])
    keyBufPool.Put(bufp)

    return ss.addrs[cs%uint32(len(ss.addrs))], nil
}
```

这是实际项目中的一个例子，这里使用 keyBufPool 的目的是为了让 crc32.ChecksumIEEE 所使用的[]bytes 数组可以重复使用，减少 GC 的压力。

但是这里可能会有一个问题，我们没有看到 Pool 的手动回收函数。
那么是不是就意味着，如果我们的并发量不断增加，这个 Pool 的体积会不断变大，或者一直维持在很大的范围内呢？

答案是不会的，sync.Pool 的回收是有的，它是在系统自动 GC 的时候，触发 pool.go 中的 poolCleanup 函数。

```golang
func poolCleanup() {
    for i, p := range allPools {
        allPools[i] = nil
        for i := 0; i < int(p.localSize); i++ {
            l := indexLocal(p.local, i)
            l.private = nil
            for j := range l.shared {
                l.shared[j] = nil
            }
            l.shared = nil
        }
        p.local = nil
        p.localSize = 0
    }
    allPools = []*Pool{}
}
```

这个函数会把 Pool 中所有 goroutine 创建的对象都进行销毁。

那这里另外一个问题也凸显出来了，很可能我上一步刚往 pool 中 PUT 一个对象之后，下一步 GC 触发，导致 pool 的 GET 函数获取不到 PUT 进去的对象。
这个时候，GET 函数就会调用 New 函数，临时创建出一个对象，并存放到 pool 中。

根据以上结论，sync.Pool 其实不适合用来做持久保存的对象池（比如连接池）。它更适合用来做临时对象池，目的是为了降低 GC 的压力。

连接池性能测试

```golang
package main

import (
    "sync"
    "testing"
)

var bytePool = sync.Pool{
    New: newPool,
}

func newPool() interface{} {
    b := make([]byte, 1024)
    return &b
}
func BenchmarkAlloc(b *testing.B) {
    for i := 0; i < b.N; i++ {
        obj := make([]byte, 1024)
        _ = obj
    }
}

func BenchmarkPool(b *testing.B) {
    for i := 0; i < b.N; i++ {
        obj := bytePool.Get().(*[]byte)
        _ = obj
        bytePool.Put(obj)
    }
}
```

文件目录下执行 `go test -bench . `

```
E:\MyGo\sync>go test -bench .
testing: warning: no tests to run
PASS
BenchmarkAlloc-4        50000000                39.3 ns/op
BenchmarkPool-4         50000000                25.4 ns/op
ok      _/E_/MyGo/sync  3.345s
```

通过性能测试可以清楚地看到，使用连接池消耗的 CPU 时间远远小于每次手动分配内存。

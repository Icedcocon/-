# Neural Networks-总结

- **(1) `nn`包用于构建神经网络，依赖`autograd`包来定义模型并求导。**
- **(2) `nn.Module`含网络各层和`forward(input)`方法，该方法返回`output`。**
- **(3) 神经网络的典型训练过程如下：**
  - 1. 定义包含一些可学习的参数(或者叫权重)神经网络模型； 
  - 2. 在数据集上迭代； 
  - 3. 通过神经网络处理输入； 
  - 4. 计算损失(输出结果和正确值的差值大小)；
  - 5. 将梯度反向传播回网络的参数； 
  - 6. 更新网络的参数，主要使用如下简单的更新原则： 
       - `weight = weight - learning_rate * gradient`

# Neural Networks

使用torch.nn包来构建神经网络。

上一讲已经讲过了``autograd``，``nn``包依赖``autograd``包来定义模型并求导。
一个``nn.Module``包含各个层和一个``forward(input)``方法，该方法返回``output``。

例如：

![](https://pytorch.org/tutorials/_images/mnist.png)

它是一个简单的前馈神经网络，它接受一个输入，然后一层接着一层地传递，最后输出计算的结果。

神经网络的典型训练过程如下：

1. 定义包含一些可学习的参数(或者叫权重)神经网络模型； 
2. 在数据集上迭代； 
3. 通过神经网络处理输入； 
4. 计算损失(输出结果和正确值的差值大小)；
5. 将梯度反向传播回网络的参数； 
6. 更新网络的参数，主要使用如下简单的更新原则： 
   ``weight = weight - learning_rate * gradient``

# Codellama部署指南

## 一、 资源

### 参考文档

- awq、gptq、guff等类型模型下载位置

https://huggingface.co/TheBloke

- xinference仓库

https://github.com/xorbitsai/inference/blob/main/README_zh_CN.md

- xinference文档

https://inference.readthedocs.io/zh-cn/latest/getting_started/installation.html

- 比较有用的博客 lamma.cpp部署

https://www.bingal.com/posts/codefuse-llama.cpp-usage/#%E5%AE%89%E8%A3%85-llama-cpp-python

[Code Llama 本地部署使用指南，并在 VSCode 和 chatbox 中使用 | BUG王](https://www.bingal.com/posts/code-llama-usage/#%E4%B8%8B%E8%BD%BD%E6%A8%A1%E5%9E%8B)

- 可部署的仓库

https://huggingface.co/TheBloke/CodeFuse-CodeLlama-34B-GPTQ/tree/main
